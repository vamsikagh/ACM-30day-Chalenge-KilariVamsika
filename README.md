# ACM 30-Day Machine Learning Challenge – Kilari Vamsika
# cycle1

---

## Daily Progress

| Day | Task Summary |
|-----|--------------|
| **Day 1** | Performed basic data cleaning and exploratory data analysis (EDA) on a burnout dataset. Handled missing values, explored distributions, and generated summary statistics. |
| **Day 2** | Applied preprocessing techniques for machine learning. Encoded categorical variables using OneHotEncoder and combined them with scaled numerical features to prepare the dataset for modeling. Performed Regression and decided which is best among three the types. |
| **Day 3** | Preprocessed data using one-hot encoding and scaling. Trained Logistic Regression and LDA models to classify burnout, then evaluated them using Accuracy, Confusion Matrix, and ROC-AUC with ROC curve visualization. |
| **Day 4**  | Trained Decision Tree, Random Forest, and k-NN models. Used Mutual Information to pick top 3 features and compared model accuracy before and after feature selection. |
| **Day 5**  | A Random Forest model predicts burnout risk after encoding and scaling the data. The top 3 features were used to build a simpler model without losing accuracy. A heatmap shows how these features relate to each other. |
| **Main Challenge**  | This model predicts medical insurance costs after cleaning and preprocessing the data. Tested different regression methods to find the best fit. Using mutual info, we picked the most important features and trained a Random Forest model for better accuracy. The final model gives reliable predictions with a solid R² score. It's efficient yet powerful enough for real-world use. |





---

## Repository Contents

- `Day1.ipynb` – Data cleaning and exploration
- `Day2.ipynb` – Feature encoding and preprocessing
- `Day3.ipynb` - Classifier Arena
- `Day4.ipynb` - Tree-Based Models + k-NN + Feature Selection
- `Day5.ipynb` - 3-Feature Showdown

---

## Tools & Libraries Used
- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib / Seaborn (for visualization, where applicable)
---
